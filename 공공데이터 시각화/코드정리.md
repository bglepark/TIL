# 3조 데이터분석 코드정리

1. 구별 / 편의시설별 데이터 전처리 -> 기능구현팀 전달

2. 데이터 어떻게 분석할건지 논의 및 데이터  column 통일화/전처리

   구별 -> 편의시설의 분포도 => 정규분포



- 전체 서울시 내 편의시설+주차장+도서관 분포현황

- 구별 편의시설+주차장,도서관 분포현황



문제제기

- 1. 장애인전용 맵 존재 x

  2. 장애인 인구 수 분포별 편의시설 분포도 / 유의차 / 타당성 분석

  3. 장애인을 위한 법 제도의 한계

  4. 장애인관련 제도적/경제적인 문제점

  5.  장애인 관련된 부실한 법(?) 혹은 사회현상으로 인한 지해사례/문제사례 (국/해외)

  6. 장애인 편의시설 추가 설치 위치

  7. 민영주차장이 의무가 아니어서 발생되는 이슈/법제도의 한계

     

     

     



## 경도, 위도 추출

* 서울특별시 장애인 관광편의시설 정보.csv 파일에 대해 전처리
* google geocoding api를 사용하여 도로명 주소를 경도와 위도로 변환하여 추가
* googlemaps 라이브러리 설치 필요

```python
import pandas as pd
import googlemaps
import numpy as np

data = pd.read_csv('서울특별시 장애인 관광편의시설 정보.csv' , encoding='cp949')

address = data['주소']
googlemaps_key = "AIzaSyDUcaVK-cevl3m70wFhRowUa5SgANfXxmM"
gmaps = googlemaps.Client(key=googlemaps_key)


lst=[]

for i in range(len(address)):
    a = address[i].split(' ')
    b = " ".join(a[0:4])
    lst.append(b)

lat = list()
lng = list()
for i, location in enumerate(lst):
    try:
        geo_location = gmaps.geocode(location)[0].get('geometry')
        lat.append(geo_location['location']['lat'])
        lng.append(geo_location['location']['lng'])
    except:
        print(f"{i}번째 {(data.iloc[i, 3])}의 좌표를 찾을 수 없음")
        lat.append(np.nan)
        lng.append(np.nan)


data['위도']=lat
data['경도']=lng
print(data.head())
data.to_csv('서울특별시 장애인 관광편의시설 정보_위도_경도.csv' ,encoding='utf-8-sig')
```



## 편의시설별 분류 및 컬럼 제거

- 공공기관

- 교육기관

- 종교시설

- 마트

- 화장실

- 의료시설

- 은행

- 영화관

  으로 분류함

```python
import pandas as pd
import numpy as np

data = pd.read_csv('서울특별시 장애인 관광편의시설 정보_위도_경도.csv')

print(data.head())
fac = data['시설명']
print(fac.head())


condition1 = (fac.str.contains('우체국|주민센터|구청|회관|공단|국민|경찰|파출|치안|세무서|지구대')) #공공기관
condition2 = fac.str.contains('초등학교|중학교|고등학교|대학교|어린이집|유치원|학원|도서관|청소년|초|증|고') #교육기관
condition3 = fac.str.contains('교회|성당') #종교시설
condition4 = fac.str.contains('마트|시장|백화점|홈플러스|마켓') #마트
condition5 = fac.str.contains('화장실')#화장실
condition6 = fac.str.contains('병원|장례식장|내과|외과|보건|이비인|치과|의원|재활|관절|안과') #의료시설
condition7 = fac.str.contains('은행') #은행
condition8 = fac.str.contains('CGV|시네마|메가박스') #영화관
condition9 = ~(condition1&condition2&condition3&condition4&condition5&condition6&condition7&condition8)




data['시설분류'] = np.nan
data.loc[condition1, '시설분류'] = '공공기관'
data.loc[condition2 , '시설분류'] = '교육기관'
data.loc[condition3 , '시설분류'] = '종교시설'
data.loc[condition4 , '시설분류'] = '마트'
data.loc[condition5 , '시설분류'] = '화장실'
data.loc[condition6 , '시설분류'] = '의료시설'
data.loc[condition7 , '시설분류'] = '은행'
data.loc[condition8 , '시설분류'] = '영화관'
# data[~condition9]='기타'

data.시설분류.replace(to_replace=np.nan, value='기타')

data.to_csv('관광편의시설정보 시설별 분류.csv' , encoding='utf-8-sig')
```



## 서울특별시 주차장 크롤링

- http://parking.seoul.go.kr/ 
- 해당 사이트에서 각 구에 해당되는 주차장 정보 크롤링
- http://parking.seoul.go.kr/SearchParkingBy.do
- json 파일로 추출

```python
# -*- coding:utf-8 -*-

import requests
import json

url = "http://parking.seoul.go.kr/SearchParkingBy.do"

gu_list = ["강남구", "강동구", "강북구", "강서구", "관악구", "광진구", "구로구", "금천구", "노원구", "도봉구",
           "동대문구", "동작구", "마포구", "서대문구", "서초구", "성동구", "성북구", "송파구", "양천구",
           "영등포구", "용산구", "은평구", "종로구", "중구", "중랑구"]
def siDo():
    total_list = []
    for i in gu_list:
        p_list = []
        res = requests.post(url, data={"Gu": i,
                                    "Dong": "전체",
                                    "Keyword": ""})
        datas = res.json()['res_value']['parking_list']
        for data in datas:
            dic = {}
            dic['name'] = data['parking_name']
            dic['capacity'] = data['capacity']
            dic['addr'] = data['address']
            dic['lng'] = data['position_list'][0]['lng']
            dic['lat'] = data['position_list'][0]['lat']
            dic['add_rates'] = data['add_rates']
            dic['rates'] = data['rates']

            p_list.append(dic)

        total_list.append(p_list)
    total_dic = {"total":total_list}

    result_json = json.dumps(total_dic, ensure_ascii=False)

    with open('seoulparking.json', 'w', encoding='utf-8') as f:
        f.write(result_json)

siDo()
```



## 주차장.json -> 주차장.csv

- dictionary 형태에서 'total'의 키값을 추출
- 각 해당 값을 리스트에 append 한 후 DataFrame 형태로 변환

```python
import pandas as pd
import json

with open('seoulparking.json' , 'r' , encoding='UTF-8') as f:
    contents = json.load(f)


# print(contents)
# print(len(contents))
name = []
capacity = []
addr = []
lng = []
lat = []

content = contents.get('total')


for i in range(len(content)):
    for j in range(len(content[i])):
        name.append(content[i][j].get('name'))
        addr.append(content[i][j].get('addr'))
        capacity.append(content[i][j].get('capacity'))
        lat.append(content[i][j].get('lat'))
        lng.append(content[i][j].get('lng'))

gu_list = ["강남구", "강동구", "강북구", "강서구", "관악구", "광진구", "구로구", "금천구", "노원구", "도봉구",
           "동대문구", "동작구", "마포구", "서대문구", "서초구", "성동구", "성북구", "송파구", "양천구",
           "영등포구", "용산구", "은평구", "종로구", "중구", "중랑구"]

gu = []
detail = []
detail2 = []

for i in range(len(content)):
    for _ in range(len(content[i])):
        gu.append(gu_list[i])
        detail.append('주차장')
        detail2.append('공영주차장')


for i in range(len(name)):
    if(name[i].find('(민영)'))>0:
        detail2[i]='민영주차장'
    else:
        continue




df = pd.DataFrame({'시설명':name , '담당구':gu, '주차가능면' : capacity , '주소':addr , '위도' : lat , '경도':lng ,
                   '시설분류' : detail , '세부분류':detail2})
print(df)
df.to_csv('(final)seoulparking.csv' , encoding='utf-8-sig' , index=False)
```



## 공영주차장 시각화

- 주차장법 시행규칙에 의거하여 각 주차장의 장애인 주차칸 여부를 추측
- 민영주차장을 제외하고 노상/노외/부설 주차장에 대해서 추측
- 노상 : 20대 이상 / 노외 : 50대 이상 / 부설 : 10대 이상
- 공공데이터 포털 내 서울시 공영주차장.csv와 매칭하여 전처리 진행
- plotly 의 express 라이브러리를 사용하여 treemap 구성
- groupby로 각 주차장의 개수를 트리맵의 면적으로
- 장애인 주차칸 가능 비율을 colorbar로 표기



```python
import pandas as pd
import matplotlib.font_manager as fm
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import plotly.express as px

font_list = [font.name for font in fm.fontManager.ttflist]

plt.rcParams['font.family'] = 'HYGothic-Medium'

# 최종 csv
# 서울특별시 주차정보안내시스템에서 민영주차장은 제거
# 노상주차장 : 20대 이상 -> 장애인 주차가능
# 노외주차장 : 50대 이상 -> 장애인 주차가능
# 부설주차장 : 10대 이상 -> 장애인 주차가능

data = pd.read_csv('(final_장애인주차가능여부)seoulparking.csv')
public = data['세부분류'] == '공영주차장'
data_public = data[public]

# 불필요한 컬럼 제거
data_public = data_public.drop(columns=['주차가능면'])
data_public = data_public.drop(columns=['시설분류'])
data_public = data_public.drop(columns=['세부분류'])
data_public = data_public.drop(columns=['주소'])
data_public = data_public.drop(columns=['위도'])
data_public = data_public.drop(columns=['경도'])
# print(data_public)


data_group = data_public.groupby(['담당구' , '장애인 주차칸 여부'] , as_index=False).count()



gu = [] #지역구

# 각 구마다가 주차가능/주차불가능 으로 나열되기 때문에 구이름 추출만을 위해서는 간격을 두개씩 해서 추출
for i in range(0, len(data_group.values), 2):
    gu.append(data_group.values[i][0])


# 컬럼명 재설정
data_group.rename(columns={'시설명':'주차장 수'} , inplace= True)
data_group['장애인 주차칸 여부'] = data_group['장애인 주차칸 여부'].replace('가능' , '주차 가능')
data_group['장애인 주차칸 여부'] = data_group['장애인 주차칸 여부'].replace('불가능' , '주차 불가능')

# print(data_group)
# print(data_group.values)

value = data_group.values.copy()
data_group['장애인 주차칸 비율(%)']=""
ratio = data_group['장애인 주차칸 비율(%)'].copy()

# 주차가능/주차불가능 비율 계산
for i in range(len(value)):
    if i == 0:
        ratio[i] = round(value[i][2]/(value[i][2]+value[i+1][2]),2)*100
    elif i%2 ==0:
        ratio[i] = round(
            value[i][2] / (value[i][2] + value[i + 1][2]), 2) * 100

    elif i%2 == 1:
        ratio[i] = round(
            value[i][2] / (value[i][2] + value[i - 1][2]), 2) * 100

data_group['장애인 주차칸 비율(%)'] = ratio
# print(data_group)
data_group['장애인 주차칸 비율(%)'] = data_group['장애인 주차칸 비율(%)'].astype(int)
# print(data_group)
# # print(round(data_group.values[0][2]/(data_group.values[0][2]+data_group.values[1][2])))
# # print(data_group.values[0][2])
# # print(data_group.values[1][2])
# # print(round((data_group.values[0][2] / (data_group.values[0][2]+data_group.values[1][2])) , 2))

# plotyly.express의 treemap 사용
fig = px.treemap(data_group,
                 path=['담당구', '장애인 주차칸 여부'],
                 values='주차장 수', # 각 구에 대한 면적은 주차장 수에 비례
                 color='장애인 주차칸 비율(%)', #color-bar는 주차장 비율에 비례
color_continuous_scale='RdBu'

                  )

fig.update_layout(title="각 구별 공영 주차장 수/장애인 주차칸 여부",
                margin = dict(t=50, l=25, r=25, b=25),
                  width=1000, height=600,)

fig.show()


```





## 워드클라우드

- https://www.bigkinds.or.kr/
- 빅카인즈에서 2017-2021(5개년) 데이터 추출
- 뉴스 검색 카테고리 : 사회
- stopwords 지정한 후 Counter 라이브러리 사용하여 키/갑 : 해당단어/횟수 형태로 변환
- top60을 추출한 뒤 워드클라우드 이미지에 삽입

```python
from wordcloud import WordCloud
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from collections import Counter
from IPython.display import set_matplotlib_formats 



data = pd.read_csv('뉴스 키워드_2017_2021.csv' , encoding='utf-8-sig')
key_words = data['특성추출(가중치순 상위 50개)']
key_word = list()

for i in range(len(key_words)):
    word = key_words[i].split(',')
    key_word.extend(word)
print(len(key_word))


stop_words = ['장애인' , '장애인들'  , '그동안' , '편의 시설' , '편의' , '시설' , '관계자' , '사업비' , '만큼' , '위원회' ,'비장애인' ,'무장애'] #제외할 단어들

key_word = [word for word in key_word if not word in stop_words]
print(len(key_word))
# print(key_word)

counts = Counter(key_word)
tags = counts.most_common(60) # top60개 뽑음 / dict 형태로 출력
print(tags)


masking_img = np.array(Image.open('4.png'))
cloud = WordCloud(font_path='Goyang.ttf' , max_font_size=400,
                  mask=masking_img , background_color='white' , colormap='coolwarm',
                  width=800, height=800).fit_words(dict(tags))
set_matplotlib_formats('retina')


cloud.to_file('wordcloud2.png')

plt.imshow(cloud, interpolation='bilinear' )
plt.axis('off')
plt.show()
```



## 콜택시 이용 정보 시각화

- os 라이브러리를 사용하여 경로를 지정한 뒤 하위 csv를 모두 concat
- 결측값은 제외하고 datetime으로 변환하기 위해 부족한 시간 정보는 00으로 추가(ex : 00초 추가)
- 문자열로 나타난 data를 datetime으로 변환
- 해당 datetime에서 요일 정보를 추출한 뒤 미리 지정한 dateDict에서 키/값 추출하여 바로 요일로 변환
- 해당 datetime을 index로 설정(between_time 사용을 위함)

- 아침/점심/저녁/심야 시간대로 나누어 구별된 컬럼 추가

  

  1. 전처리

  ```python
  import pandas as pd
  from datetime import datetime
  import numpy as np
  
  ## 이전 모든 csv를 한번에 합치는 코드
  ## os 라이브러리를 사용해서 해당 경로에 있는 파일을 전부 불러와서 concat
  
  # data_list = os.listdir('C:/PythonStudy/taxi/')
  # data_all = pd.DataFrame()
  #
  # % cd
  # C: / PythonStudy / taxi /
  #
  # for files in data_list:
  #     df = pd.read_csv(files, encoding='cp949')
  #     data_all = pd.concat([data_all, df], ignore_index=True)
  
  ## datetime으로 바꾸기 위해서 각각의 누락된 값 합치기
  
  # df['운행시작1'] = ''
  # for i in range(len(drive_start)):
  #     if len(drive_start[i]) == 13:
  #         df['운행시작1'][i] = '2021' + drive_start[i][:6] + ' ' + drive_start[i][7:] + '00'
  #     elif len(drive_start[i]) == 15:
  #         df['운행시작1'][i] = '20' + drive_start[i][:8] + ' ' + drive_start[i][9:] + '00'
  #     elif len(drive_start[i]) == 19:
  #         df['운행시작1'][i] = drive_start[i][:10] + ' ' + drive_start[i][11:]
  #
  
  
  data = pd.read_csv('calltaxi.csv')
  drive_start = data['운행시작']
  
  drive_date =[] #날짜
  for i in drive_start:
      drive_date.append(datetime.strptime(i[0:10], '%Y-%m-%d')) #문자열->datetime으로 변환
  
  # datetime이 각 요일에 맞춰서 숫자로 나오기 때문에 미리 dateDict을 설정
  dateDict = {0:'월요일' , 1:'화요일' , 2:'수요일' , 3:'목요일' , 4:'금요일' , 5:'토요일' ,6:'일요일'}
  dayday = [] #요일
  for i in drive_date:
      dayday.append(dateDict[i.weekday()])
  # 바로 dateDict에서 value값 찾아서 요일로 변환
  
  
  data['운행시작'].replace('24:00','0:00', inplace=True) #중복 방지
  data['운행시작'] = pd.to_datetime(data['운행시작'] , errors='coerce') #오류 방지
  
  
  data['운행시작_시간']=data['운행시작'].dt.time
  
  data = data.drop(columns=['시동ON 시각'])
  data['요일'] = dayday
  
  data = data.set_index('운행시작') #index로 datetime을 설정해야 between_time 사용 가능 / 이후 시계열 분석
  
  morning = data.between_time('06:00:01', '12:00:00') #between_time 사용해서 시간대별로 구분
  afternoon = data.between_time('12:00:01', '18:00:00')
  evening = data.between_time('18:00:01', '00:00:00')
  midnight = data.between_time('00:00:01', '06:00:00')
  
  data['구분']= 'N/A'
  data.loc[morning.index, '구분'] = '아침'
  data.loc[afternoon.index, '구분'] = '점심'
  data.loc[evening.index, '구분'] = '저녁'
  data.loc[midnight.index, '구분'] = '심야'
  
  data.to_csv('calltaxi_전처리완료.csv' ,  encoding='utf-8-sig')
  
  ```



2. 시계열 그래프

   - between_time 이용하여 시간대별로 나눈 후 value_counts()로 각 횟수 count

   - 평균 값에 대해서 수평선 추가 및 text로 값 표시

     

   ```python
   import pandas as pd
   import matplotlib.pyplot as plt
   
   import matplotlib.font_manager as fm
   
   font_list = [font.name for font in fm.fontManager.ttflist]
   plt.rcParams['font.family'] = 'HYGothic-Medium' # 폰트 설정
   
   data = pd.read_csv('calltaxi_전처리완료.csv' , encoding='utf-8-sig')
   
   data['운행시작'] = pd.to_datetime(data['운행시작'] , errors='coerce') #오류 방지
   data = data.set_index('운행시작')
   
   
   data['운행시작_시간대별'] = 'N/A'
   
   time01 = data.between_time('01:00:01', '02:00:00')
   time02 = data.between_time('02:00:01', '03:00:00')
   time03 = data.between_time('03:00:01', '04:00:00')
   time04 = data.between_time('04:00:01', '05:00:00')
   time05 = data.between_time('05:00:01', '06:00:00')
   time06 = data.between_time('06:00:01', '07:00:00')
   time07 = data.between_time('07:00:01', '08:00:00')
   time08 = data.between_time('08:00:01', '09:00:00')
   time09 = data.between_time('09:00:01', '10:00:00')
   time10 = data.between_time('10:00:01', '11:00:00')
   time11 = data.between_time('11:00:01', '12:00:00')
   time12 = data.between_time('12:00:01', '13:00:00')
   time13 = data.between_time('13:00:01', '14:00:00')
   time14 = data.between_time('14:00:01', '15:00:00')
   time15 = data.between_time('15:00:01', '16:00:00')
   time16 = data.between_time('16:00:01', '17:00:00')
   time17 = data.between_time('17:00:01', '18:00:00')
   time18 = data.between_time('18:00:01', '19:00:00')
   time19 = data.between_time('19:00:01', '20:00:00')
   time20 = data.between_time('20:00:01', '21:00:00')
   time21 = data.between_time('21:00:01', '22:00:00')
   time22 = data.between_time('22:00:01', '23:00:00')
   time23 = data.between_time('23:00:01', '00:00:00')
   time24 = data.between_time('00:00:01', '01:00:00')
   #
   data.loc[time01.index, '운행시작_시간대별'] = '01시'
   data.loc[time02.index, '운행시작_시간대별'] = '02시'
   data.loc[time03.index, '운행시작_시간대별'] = '03시'
   data.loc[time04.index, '운행시작_시간대별'] = '04시'
   data.loc[time05.index, '운행시작_시간대별'] = '05시'
   data.loc[time06.index, '운행시작_시간대별'] = '06시'
   data.loc[time07.index, '운행시작_시간대별'] = '07시'
   data.loc[time08.index, '운행시작_시간대별'] = '08시'
   data.loc[time09.index, '운행시작_시간대별'] = '09시'
   data.loc[time10.index, '운행시작_시간대별'] = '10시'
   data.loc[time11.index, '운행시작_시간대별'] = '11시'
   data.loc[time12.index, '운행시작_시간대별'] = '12시'
   data.loc[time13.index, '운행시작_시간대별'] = '13시'
   data.loc[time14.index, '운행시작_시간대별'] = '14시'
   data.loc[time15.index, '운행시작_시간대별'] = '15시'
   data.loc[time16.index, '운행시작_시간대별'] = '16시'
   data.loc[time17.index, '운행시작_시간대별'] = '17시'
   data.loc[time18.index, '운행시작_시간대별'] = '18시'
   data.loc[time19.index, '운행시작_시간대별'] = '19시'
   data.loc[time20.index, '운행시작_시간대별'] = '20시'
   data.loc[time21.index, '운행시작_시간대별'] = '21시'
   data.loc[time22.index, '운행시작_시간대별'] = '22시'
   data.loc[time23.index, '운행시작_시간대별'] = '23시'
   data.loc[time24.index, '운행시작_시간대별'] = '24시'
   
   
   
   data_time_counting = data['운행시작_시간대별'].value_counts() # 각 시간대별로 개수 count
   
   data_time_counting_sort = data_time_counting.sort_index() # index에 따라서 순서 나열
   
   
   # 라벨링 만들기
   labels = []
   for i in data_time_counting_sort.index:
       labels.append(i)
   # print(labels)
   
   
   # 값(values 설정)
   values = data_time_counting_sort.values
   label = "콜택시"
   plt.figure(figsize=(20,10))
   plt.plot(labels, values, marker='s' , color='royalblue' , label=label)
   plt.grid(axis='y')
   plt.axhline(y= values.mean(), linestyle='--', color='C8', label="평균횟수") #수평선 추가
   plt.text(20 , values.mean()+130 , f'평균횟수 : {round(values.mean() , )}회' , fontsize=16) # 수평선 위에 text 넣기
   
   plt.title("시간대별 장애인 콜택시 이용 현황" , fontsize = 24)
   plt.xlabel('시간대별' , fontsize= 20)
   plt.ylabel('이용 횟수' , fontsize = 20)
   plt.xticks(fontsize=14)
   plt.yticks(fontsize=16)
   plt.legend()
   plt.legend(fontsize =16)
   plt.show()
   
   ```



3. 요일별 그래프

```python
import pandas as pd
import matplotlib.pyplot as plt

import matplotlib.font_manager as fm

font_list = [font.name for font in fm.fontManager.ttflist]

plt.rcParams['font.family'] = 'HYGothic-Medium'

data = pd.read_csv('calltaxi_전처리완료.csv')


# 아침
morning = data[data['구분']=='아침']
morning_day = morning['요일'].value_counts()
morning_dayday = morning_day.reindex(['월요일' , '화요일' , '수요일' , '목요일' , '금요일' , '토요일' , '일요일']) # 순서대로 reindex
morning_values = morning_dayday.values

# 점심
afternoon = data[data['구분']=='점심']
afternoon_day = afternoon['요일'].value_counts()
afternoon_dayday = afternoon_day.reindex(['월요일' , '화요일' , '수요일' , '목요일' , '금요일' , '토요일' , '일요일']) # 순서대로 reindex
afternoon_values = afternoon_dayday.values

#저녁
evening = data[data['구분']=='저녁']
evening_day = evening['요일'].value_counts()
evening_dayday = evening_day.reindex(['월요일' , '화요일' , '수요일' , '목요일' , '금요일' , '토요일' , '일요일']) # 순서대로 reindex
evening_values = evening_dayday.values

#심야
midnight = data[data['구분']=='심야']
midnight_day = midnight['요일'].value_counts()
midnight_dayday = midnight_day.reindex(['월요일' , '화요일' , '수요일' , '목요일' , '금요일' , '토요일' , '일요일']) # 순서대로 reindex
midnight_values = midnight_dayday.values

labels = []
for i in morning_dayday.index:
    labels.append(i)



plt.figure(figsize=(16,12))
plt.title('요일별 운행횟수', fontsize=26)
plt.ylabel('운행 횟수', fontsize=24)
plt.xlabel('요일', fontsize=24)

p_morning = plt.bar(labels, morning_values, color='C0',  label='아침(6시~12시' , alpha=0.7 )
p_afternoon = plt.bar(labels, afternoon_values, color='C0' ,  label='점심(12시~18시)' , alpha=0.5,
                      bottom=morning_values) #bottom을 이용해서 stack 기능 설정
p_evening = plt.bar(labels, evening_values, color = 'C0' ,  label = '저녁(18시~24시)' ,alpha=0.3,
                    bottom=afternoon_values+morning_values)
p_midnight = plt.bar(labels, midnight_values , color = 'C0' ,  label = '심야(24시~6시)', alpha=0.1,
                     bottom=morning_values+afternoon_values+evening_values)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.text(-0.1, 2000 , '39%' , fontsize=16) #월/아침
plt.text(0.9, 2000 , '41%' , fontsize=16) # 화/아침
plt.text(1.9, 2000 , '42%' , fontsize=16) # 수/아침
plt.text(2.9, 2000 , '42%' , fontsize=16) #목/아침
plt.text(3.9, 2000 , '42%' , fontsize=16) #금/아침
plt.text(4.9, 1300 , '43%' , fontsize=16) #토/아침
plt.text(5.9, 1000 , '39%' , fontsize=16) #일/아침

plt.text(-0.1, 6200 , '45%' , fontsize=16) #월/점심
plt.text(0.9, 6200 , '45%' , fontsize=16) #화/점심
plt.text(1.9, 6100 , '44%' , fontsize=16) #수/점심
plt.text(2.9, 6150 , '44%' , fontsize=16) #목/점심
plt.text(3.9, 6200 , '44%' , fontsize=16) #금/점심
plt.text(4.9, 3900 , '40%' , fontsize=16) #토/점심
plt.text(5.9, 3400 , '45%' , fontsize=16) #일/점심

plt.text(-0.1, 9200 , '13%' , fontsize=16) #월/저녁
plt.text(0.9, 9000 , '12%' , fontsize=16) #화/저녁
plt.text(1.9, 8600 , '11%' , fontsize=16) #수/저녁
plt.text(2.9, 8850 , '12%' , fontsize=16) #목/저녁
plt.text(3.9, 8950 , '11%' , fontsize=16) #금/저녁
plt.text(4.9, 5500 , '14%' , fontsize=16) #토/저녁
plt.text(5.9, 5200 , '15%' , fontsize=16) #일/저녁

plt.legend()
plt.legend(fontsize =14)
plt.show()



# 요일별 비율
import pandas as pd
# import matplotlib.pyplot as plt
# 
# import matplotlib.font_manager as fm
# 
# font_list = [font.name for font in fm.fontManager.ttflist]
# # print(font_list)
# plt.rcParams['font.family'] = 'HYGothic-Medium'
# 
# data = pd.read_csv('calltaxi_전처리완료.csv')
# 
# #월요일
# monday = data[data['요일']=='월요일']
# monday_day = monday['구분'].value_counts(normalize=True)
# # print(round(monday_day*100))
# #점심    45.0
# # 아침    39.0
# # 저녁    13.0
# # 심야     3.0
# 
# tuesday = data[data['요일']=='화요일']
# tuesday_day = tuesday['구분'].value_counts(normalize=True)
# # print(round(tuesday_day*100))
# # 점심    45.0
# # 아침    41.0
# # 저녁    12.0
# # 심야     2.0
# 
# wday = data[data['요일']=='수요일']
# wday_day = wday['구분'].value_counts(normalize=True)
# # print(round(wday_day*100))
# # 점심    44.0
# # 아침    42.0
# # 저녁    11.0
# # 심야     2.0
# 
# thursday = data[data['요일']=='목요일']
# thursday_day = thursday['구분'].value_counts(normalize=True)
# # print(round(thursday_day*100))
# # 점심    44.0
# # 아침    42.0
# # 저녁    12.0
# # 심야     2.0
# 
# friday = data[data['요일']=='금요일']
# friday_day = friday['구분'].value_counts(normalize=True)
# # print(round(friday_day*100))
# # 점심    44.0
# # 아침    42.0
# # 저녁    11.0
# # 심야     3.0
# 
# saturday = data[data['요일']=='토요일']
# saturday_day = saturday['구분'].value_counts(normalize=True)
# print(round(saturday_day*100))
# # 아침    43.0
# # 점심    40.0
# # 저녁    14.0
# # 심야     4.0
# 
# sunday = data[data['요일']=='일요일']
# sunday_day = sunday['구분'].value_counts(normalize=True)
# print(round(sunday_day*100))
# # 점심    45.0
# # 아침    36.0
# # 저녁    15.0
# # 심야     4.0
```



## 구별 장애인 수 count

- 기존 raw data에서 자치구와 합계를 추출하여 DataFrame 재구성
- folium.Choropleth 사용하여 지도 구성
- https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json
- 해당 json에서 각 구에 대한 경도 위도 정보를 가져옴

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import folium
df1 = pd.read_csv('구별 장애인 수.csv', encoding='utf-8-sig')

df1 = df1.loc[3:,['자치구', '합계']]

df1.reset_index(drop=True, inplace=True)

for i, data in enumerate(df1['합계']):
    df1['합계'][i] = data.replace(',', '')

df1['합계'] = df1['합계'].astype('int')

df1.index = df1['자치구']
del df1['자치구']
df1
m = folium.Map(location=[37.562225, 126.978555], tiles="OpenStreetMap", zoom_start=11)

state_geo = 'https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json'
# 각각의 구에 대한 경도,위도 정보 가져옴

folium.Choropleth(
    geo_data = state_geo,
    data = df1['합계'],
    key_on = 'feature.properties.name', #feature 타입의 properties의 name을 key로 설정
    fill_color = 'BuPu',
    # fill_opacity=0.7,
    # line_opacity=0.3,
    bins = [5000,10000,15000,20000,25000,30000], #bins로 구간 나누기
).add_to(m)
m.save('disabled_count.html')
```



